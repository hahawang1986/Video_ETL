{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()\n",
    "#!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is for correct the file-format, because some chinese sign cann't be read by utf-8\n",
    "# from pyspark.sql import SparkSession\n",
    "# from pyspark.sql.functions import col, array_contains, split, when, regexp_replace\n",
    "\n",
    "# # creat SparkSession\n",
    "# spark = SparkSession.builder \\\n",
    "#     .appName(\"ETL_media\") \\\n",
    "#     .getOrCreate()\n",
    "# #file_path = r'F:\\申请，润\\我去澳洲\\university of adelaide\\AWS\\video_data.csv'\n",
    "# # load CSV \n",
    "# # File layout - inferSchema \n",
    "# # Field delimiter – pipe, tab, comma\n",
    "# # File encoding – ASCII, UTF-8, UTF-16,gb2312 中文字符\n",
    "# # API - read.csv\n",
    "# #df = spark.read.csv(file_path, header=True, inferSchema=True,encoding=\"gb2312\")\n",
    "# df = spark.read.csv(\"video_data.csv\", header=True, inferSchema=True,encoding=\"gb2312\") # automately recognize the type of data\n",
    "# df = df.drop(\"_c3\")\n",
    "# df.show(1,truncate=False)\n",
    "\n",
    "# df = df.withColumn(\"VideoTitle\", regexp_replace(col(\"VideoTitle\"), \"’\", \"'\")) \\\n",
    "#        .withColumn(\"VideoTitle\", regexp_replace(col(\"VideoTitle\"), \"‘\", \"'\")) \\\n",
    "#         .withColumn(\"VideoTitle\", regexp_replace(col(\"VideoTitle\"), \"”\", \"\\\"\")) \\\n",
    "#         .withColumn(\"VideoTitle\", regexp_replace(col(\"VideoTitle\"), \"“\", \"\\\"\"))\n",
    "# df.show(200,truncate=False)\n",
    "# file_name1 = r\"F:\\申请，润\\我去澳洲\\university of adelaide\\AWS\\ETL\\source\"\n",
    "# df.coalesce(1).write.csv(file_name1, mode='overwrite', header=True, encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Executor Memory: 8g\n",
      "Spark Driver Memory: 4g\n",
      "Spark Executor Cores: 4\n",
      "Spark Driver Cores: 1\n",
      "+-------------------+---------------------------------------------------------+-----------------------------------------------+\n",
      "|DateTime           |VideoTitle                                               |events                                         |\n",
      "+-------------------+---------------------------------------------------------+-----------------------------------------------+\n",
      "|2024-01-11 10:30:31|App Web|Clips|a-current-affair;2016|William Tyrrell twist|157,120,160,104,162,000,000,000,000,000,000,000|\n",
      "+-------------------+---------------------------------------------------------+-----------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import findspark \n",
    "\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, array_contains, split, when, regexp_replace\n",
    "\n",
    "# creat SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ETL_media\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.cores\", \"4\") \\\n",
    "    .config(\"spark.driver.cores\", \"1\") \\\n",
    "    .getOrCreate()\n",
    "print(f\"Spark Executor Memory: {spark.conf.get('spark.executor.memory')}\")\n",
    "print(f\"Spark Driver Memory: {spark.conf.get('spark.driver.memory')}\")\n",
    "print(f\"Spark Executor Cores: {spark.conf.get('spark.executor.cores')}\")\n",
    "print(f\"Spark Driver Cores: {spark.conf.get('spark.driver.cores')}\")\n",
    "\n",
    "#file_path = r'F:\\申请，润\\我去澳洲\\university of adelaide\\AWS\\video_data.csv'\n",
    "# load CSV \n",
    "# File layout - inferSchema \n",
    "# Field delimiter – pipe, tab, comma\n",
    "# File encoding – ASCII, UTF-8, UTF-16,gb2312 中文字符\n",
    "# API - read.csv\n",
    "#df = spark.read.csv(file_path, header=True, inferSchema=True,encoding=\"gb2312\")\n",
    "df = spark.read.csv(\"..\\\\data_source\\\\video_data_new.csv\", header=True, inferSchema=True,encoding=\"UTF-8\") # automately recognize the type of data\n",
    "df.show(1,truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with modified cell:\n",
      "+-------------------+-----------------------------------------------------------------------+---------------------------------------------------+\n",
      "|DateTime           |VideoTitle                                                             |events                                             |\n",
      "+-------------------+-----------------------------------------------------------------------+---------------------------------------------------+\n",
      "|NULL               |App Web|Clips|a-current-affair;2016|William Tyrrell twist              |157,120,160,104,162,000,000,000,000,000,000,000    |\n",
      "|2024-01-11 10:30:53|news| Shark attacks spearfisherman                                     |127,157,120,160,104,000,000,000,000                |\n",
      "|2024-01-11 10:30:21|news| Shark attacks spearfisherman                                     |127,157,120,160,104,000,000,000,000,000,000,000,000|\n",
      "|2024-01-11 10:31:27|news| Chilean navy films UFO                                           |157,120,160,104,162,000,000,000,000                |\n",
      "|2024-01-11 10:30:33|news| Video shows alleged axe attack at Sydney service station         |157,120,160,104,162,000,000,000,000,000,000,000    |\n",
      "|2024-01-11 10:30:18|App Web|Clips|today;2024|Pint-sized Aussie surfer hits the global stage|127,157,120,160,104,000,000,000,000,000,000,000,000|\n",
      "|2024-01-11 10:30:22|news| Australian pedophile extradited to US                            |127,157,120,160,104,000,000,000,000,000,000,000,000|\n",
      "|2024-01-11 10:32:50|news| Chilean navy films UFO                                           |127,157,120,160,104,000,000,000,000,000,000,000,000|\n",
      "|2024-01-11 10:32:37|news| Australian pedophile extradited to US                            |157,120,160,104,162,000,000,000,000,000,000,000    |\n",
      "|202401#1110k33l51  |news| Chilean navy films UFO                                           |127,157,120,160,104,000,000,000,000                |\n",
      "+-------------------+-----------------------------------------------------------------------+---------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "root\n",
      " |-- DateTime: string (nullable = true)\n",
      " |-- VideoTitle: string (nullable = true)\n",
      " |-- events: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## set some wrong record for testing\n",
    "\n",
    "col_name = \"DateTime\"\n",
    "target_value = \"2024-01-11 10:30:31\"\n",
    "target_value1 = \"2024-01-11 10:33:51\"\n",
    "\n",
    "# 使用 withColumn 和 when 函数来条件性地更新特定单元格的值\n",
    "df = df.withColumn(col_name,\n",
    "                   when(col(col_name) == target_value, None).otherwise(col(col_name)))\n",
    "df = df.withColumn(col_name,\n",
    "                   when(col(col_name) == target_value1, \"202401#1110k33l51\").otherwise(col(col_name)))\n",
    "\n",
    "# 显示更新后的数据\n",
    "print(\"DataFrame with modified cell:\")\n",
    "df.show(10,truncate=False)\n",
    "df.columns\n",
    "df.count()\n",
    "df.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|id                                  |profile                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "+------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|ce9e2a92-a27d-42a4-a723-0b14061b9664|{Samantha, [{2017-11-23, Brisbane, 106000, principal, NULL}, {2013-10-03, Brisbane, 101000, dentist, 2017-11-03}, {2010-02-28, Brisbane, 99000, internal sales, 2013-09-29}, {2007-07-13, Brisbane, 98000, middleware specialist, 2010-02-13}, {2004-11-23, Brisbane, 94000, clinical psychologist, 2007-06-23}, {2002-05-05, Brisbane, 94000, specialist, 2004-11-05}, {2002-04-13, Brisbane, 92000, assistant operations manager, 2002-04-13}], Ronyak}|\n",
      "+------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- profile: struct (nullable = true)\n",
      " |    |-- firstName: string (nullable = true)\n",
      " |    |-- jobHistory: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- fromDate: string (nullable = true)\n",
      " |    |    |    |-- location: string (nullable = true)\n",
      " |    |    |    |-- salary: long (nullable = true)\n",
      " |    |    |    |-- title: string (nullable = true)\n",
      " |    |    |    |-- toDate: string (nullable = true)\n",
      " |    |-- lastName: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "190000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取JSON文件\n",
    "df_user = spark.read.json(\"..\\\\data_source\\\\user.json\")\n",
    "df_user.show(1,truncate =False)\n",
    "df_user.printSchema()\n",
    "df_user.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                  id|\n",
      "+--------------------+\n",
      "|557c2960-c218-4ee...|\n",
      "|ef4260d6-500d-4ec...|\n",
      "|5d7c0aeb-515b-4d2...|\n",
      "|c37de051-44e8-429...|\n",
      "|58abded2-f45f-4f9...|\n",
      "|ec497bd4-ac2b-4a0...|\n",
      "|436d7423-265a-49e...|\n",
      "|feff51e1-149c-4ef...|\n",
      "|116cc000-a458-4cf...|\n",
      "|824f8f2e-1512-4b8...|\n",
      "+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "190000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import broadcast\n",
    "df_user_id = df_user.na.drop().select(\"id\").distinct()\n",
    "\n",
    "df_user_id.show(10)\n",
    "df_user_id.count()\n",
    "\n",
    "# Broadcast the user IDs\n",
    "# broadcast_user_ids = spark.sparkContext.broadcast(df_user_id.collect())\n",
    "\n",
    "# 在PySpark中，使用广播变量（Broadcast Variables）时，\n",
    "# 需要将数据从分布式的Executor节点传输到驱动程序节点（Driver节点）。\n",
    "# 这是因为广播变量是在驱动程序上创建和管理的，然后将其分发到工作节点上的任务中使用。\n",
    "# 具体来说，为了在广播变量中使用DataFrame或RDD的数据，需要使用collect()方法将数据收集到驱动程序节点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nining\\AppData\\Local\\Temp\\ipykernel_9504\\4165628295.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------------------+--------------------+\n",
      "|           DateTime|          VideoTitle|              events|                  id|\n",
      "+-------------------+--------------------+--------------------+--------------------+\n",
      "|               NULL|App Web|Clips|a-c...|157,120,160,104,1...|8596d99e-f330-415...|\n",
      "|2024-01-11 10:30:53|news| Shark attac...|127,157,120,160,1...|d32959d4-e49b-4ee...|\n",
      "|2024-01-11 10:30:21|news| Shark attac...|127,157,120,160,1...|c38afb0e-1301-470...|\n",
      "|2024-01-11 10:31:27|news| Chilean nav...|157,120,160,104,1...|67885725-c514-4cf...|\n",
      "|2024-01-11 10:30:33|news| Video shows...|157,120,160,104,1...|4f08512d-bb2a-422...|\n",
      "|2024-01-11 10:30:18|App Web|Clips|tod...|127,157,120,160,1...|56f86cd6-61a2-4c3...|\n",
      "|2024-01-11 10:30:22|news| Australian ...|127,157,120,160,1...|19f9652a-1191-41e...|\n",
      "|2024-01-11 10:32:50|news| Chilean nav...|127,157,120,160,1...|a51045eb-8bed-4f5...|\n",
      "|2024-01-11 10:32:37|news| Australian ...|157,120,160,104,1...|e899f4f0-6ba4-4c2...|\n",
      "|  202401#1110k33l51|news| Chilean nav...|127,157,120,160,1...|c8fd22e8-989e-40a...|\n",
      "|2024-01-11 10:32:42|news| Chilean nav...|157,120,160,104,1...|6583477e-8c23-488...|\n",
      "|2024-01-11 10:34:01|news| Man wins bi...|127,157,120,160,1...|e17e97ed-65f4-4c7...|\n",
      "|2024-01-11 10:34:07|App Web|Clips|tod...|157,120,160,104,1...|362d51f7-ff9f-412...|\n",
      "|2024-01-11 10:32:18|news| Celebrity r...|157,120,160,104,1...|85285709-81ca-492...|\n",
      "|2024-01-11 10:34:50|news| Man wins bi...|157,120,160,104,1...|95001a60-27e6-4b3...|\n",
      "|2024-01-11 10:34:07|news|Exclusive CC...|157,120,160,104,1...|b63d2580-0d6e-4e9...|\n",
      "|2024-01-11 10:33:07|news|Blue shark w...|127,157,120,160,1...|2426fda2-a993-4d0...|\n",
      "|2024-01-11 10:36:05|news|Young Queens...|157,120,160,104,1...|7173722b-bffa-463...|\n",
      "|2024-01-11 10:35:58|news| Celebrity r...|127,157,120,160,1...|f99d3925-686b-4e3...|\n",
      "|2024-01-11 10:36:45|news| Child pulle...|157,120,160,104,1...|e92cf4bd-4853-4ee...|\n",
      "|2024-01-11 10:35:55|news| Australian ...|127,157,120,160,1...|3a4751a5-7b66-401...|\n",
      "|2024-01-11 10:35:55|news|Frog alleged...|157,120,160,104,1...|32adb31b-a3a4-481...|\n",
      "|2024-01-11 10:41:05|news| Celebrity r...|127,157,120,160,1...|d1851ec8-fb75-41a...|\n",
      "|2024-01-11 10:41:27|news| Shark attac...|127,157,120,160,1...|93ef5600-70ec-43f...|\n",
      "|2024-01-11 10:38:28|news| Shark attac...|127,157,120,160,1...|48f75721-0083-430...|\n",
      "|2024-01-11 10:41:07|news|Dramatic arr...|157,120,160,104,1...|e2199cc7-e355-4e5...|\n",
      "|2024-01-11 10:41:29|news| McDonald's ...|127,157,120,160,1...|00d76967-25bc-409...|\n",
      "|2024-01-11 10:39:48|news| Shark attac...|157,120,160,104,1...|11af1da7-fc42-4e2...|\n",
      "|2024-01-11 10:39:29|news| Massive bra...|127,157,120,160,1...|4d3e4f46-cc83-4ba...|\n",
      "|2024-01-11 10:40:56|news|Meryl Streep...|127,157,120,160,1...|74114463-3f93-4a0...|\n",
      "|2024-01-11 10:39:44|news|Gold Coast s...|157,120,160,104,1...|3ea8d664-7ee0-4fa...|\n",
      "|2024-01-11 10:41:09|news|Woman killed...|157,120,160,104,1...|88debe2e-9b3f-456...|\n",
      "|2024-01-11 10:43:07|App Web|Clips|pos...|127,157,120,160,1...|0da4cde7-5ba2-465...|\n",
      "|2024-01-11 10:43:09|news| Shark attac...|157,120,160,104,1...|033bd542-1384-4e1...|\n",
      "|2024-01-11 10:44:52|news| Avalanche b...|127,157,120,160,1...|f260b5de-1f5d-4c3...|\n",
      "|2024-01-11 10:43:26|news| Celebrity r...|157,120,160,104,1...|d9b11f3c-dee3-4f6...|\n",
      "|2024-01-11 10:43:30|news| Two men hos...|157,120,160,104,1...|fe0ce0d9-2f39-4f4...|\n",
      "|2024-01-11 10:44:55|news| Video shows...|157,120,160,104,1...|d0a6ac31-dce7-481...|\n",
      "|2024-01-11 10:42:28|news| Man wins bi...|127,157,120,160,1...|efca621c-d408-42d...|\n",
      "|2024-01-11 10:41:48|news| Avalanche b...|127,157,120,160,1...|30cb507a-02a9-4fd...|\n",
      "|2024-01-11 10:42:32|news| Avalanche b...|127,157,120,160,1...|86488bff-501b-423...|\n",
      "|2024-01-11 10:42:50|news|Young Queens...|127,157,120,160,1...|c606b491-21db-4d0...|\n",
      "|2024-01-11 10:42:45|App Web|Clips|a-c...|157,120,160,104,1...|e5f8a59a-5ed2-416...|\n",
      "|2024-01-11 10:45:09|news|Frog alleged...|127,157,120,160,1...|725af2e0-a2a7-437...|\n",
      "|2024-01-11 10:46:29|news|Mother charg...|127,157,120,160,1...|14909541-b5ee-431...|\n",
      "|2024-01-11 10:46:20|news| Shark attac...|157,120,160,104,1...|8898867d-4a33-4d5...|\n",
      "|2024-01-11 10:46:15|App Web|Clips|tod...|127,157,120,160,1...|38e4aa85-248c-40d...|\n",
      "|2024-01-11 10:45:42|news|Meryl Streep...|127,157,120,160,1...|6559dd17-d682-4f9...|\n",
      "|2024-01-11 10:46:19|news| Video shows...|127,157,120,160,1...|5570d556-282b-492...|\n",
      "|2024-01-11 10:49:00|news|Young Queens...|127,157,120,160,1...|1f937088-3dca-4ef...|\n",
      "|2024-01-11 10:47:03|news|Swimmers eva...|157,120,160,104,1...|6afdf7a4-4f00-40e...|\n",
      "|2024-01-11 10:48:28|news|Frog alleged...|127,157,120,160,1...|9cf7f579-8094-42f...|\n",
      "|2024-01-11 10:46:58|news| Chilean nav...|157,120,160,104,1...|6df51d3f-57b0-4bd...|\n",
      "|2024-01-11 10:46:46|news| Shark attac...|157,120,160,104,1...|a6a64be2-48a1-4c0...|\n",
      "|2024-01-11 10:49:22|news| Shark attac...|157,120,160,104,1...|ca0eae26-8b7f-454...|\n",
      "|2024-01-11 10:48:39|news| Driver take...|157,120,160,104,1...|c718f8d1-aad5-4ce...|\n",
      "|2024-01-11 10:49:29|news| Avalanche b...|127,157,120,160,1...|37156b95-0687-487...|\n",
      "|2024-01-11 10:47:34|news| Kim Kardash...|127,157,120,160,1...|02625335-4923-48b...|\n",
      "|2024-01-11 10:48:08|news|Mother charg...|127,157,120,160,1...|841bb2cf-bccc-4ed...|\n",
      "|2024-01-11 10:47:22|news|Pint-sized A...|127,157,120,160,1...|1d846e9a-a2bf-495...|\n",
      "|2024-01-11 10:50:39|news| Avalanche b...|127,157,120,160,1...|becfd944-56b2-446...|\n",
      "|2024-01-11 10:50:29|news| Chilean nav...|157,120,160,104,1...|ff756cdd-c1ff-411...|\n",
      "|2024-01-11 10:50:38|news|Pint-sized A...|127,157,120,160,1...|571718ae-444b-4af...|\n",
      "|2024-01-11 10:53:08|news|Frozen water...|157,120,160,104,1...|2c9a31dc-3518-44b...|\n",
      "|2024-01-11 10:53:16|news| Shark attac...|157,120,160,104,1...|b0f839ae-981b-465...|\n",
      "|2024-01-11 10:52:14|news|Woman killed...|157,120,160,104,1...|0b4eddde-90ea-446...|\n",
      "|2024-01-11 10:51:23|news| Shark attac...|157,120,160,104,1...|e28588e5-89cc-4bb...|\n",
      "|2024-01-11 10:52:31|news|Chris Sandow...|157,120,160,104,1...|8af930e5-b73c-4c9...|\n",
      "|2024-01-11 10:51:56|App Web|Clips|a-c...|127,157,120,160,1...|839623c5-8755-445...|\n",
      "|2024-01-11 10:50:25|news|Meryl Streep...|148,157,120,160,1...|b47d77a4-ea37-4ee...|\n",
      "|2024-01-11 10:55:58|news|Frog alleged...|127,157,120,160,1...|64fa8f2a-742f-4b4...|\n",
      "|2024-01-11 10:53:49|news|Cold-blooded...|157,120,160,104,1...|f202f315-fbfd-419...|\n",
      "|2024-01-11 10:56:23|news|Bali overrun...|157,120,160,104,1...|4808e322-4896-4f5...|\n",
      "|2024-01-11 10:55:47|news| Celebrity r...|157,120,160,104,1...|36ac07e1-b9af-490...|\n",
      "|2024-01-11 10:53:29|App Web|Clips|a-c...|127,157,120,160,1...|f342dba7-648a-4e9...|\n",
      "|2024-01-11 10:55:00|App Web|Clips|tod...|127,157,120,160,1...|a62637a2-2fa3-441...|\n",
      "|2024-01-11 10:53:43|news|Melbourne st...|157,120,160,104,1...|ce8ba16a-1cd7-4ca...|\n",
      "|2024-01-11 10:54:02|news| Pastor film...|127,157,120,160,1...|626cab98-73b2-40e...|\n",
      "|2024-01-11 10:56:10|news| Woman walki...|127,157,120,160,1...|a11f123f-984e-43b...|\n",
      "|2024-01-11 10:54:32|news|Cold-blooded...|157,120,160,104,1...|81e2b7e1-c899-40a...|\n",
      "|2024-01-11 10:58:54|news| Video shows...|127,157,120,160,1...|f1e07f42-7f6a-4fb...|\n",
      "|2024-01-11 10:58:21|news|Young Queens...|127,157,120,160,1...|46fd9f8c-02fb-4a7...|\n",
      "|2024-01-11 10:56:56|news| Kayaker rid...|157,120,160,104,1...|5ad48525-d9eb-4e5...|\n",
      "|2024-01-11 10:58:36|news|Meryl Streep...|127,157,120,160,1...|585cdd04-4fd0-429...|\n",
      "|2024-01-11 10:59:00|news|Sydney servo...|157,120,160,104,1...|294dbd20-636d-418...|\n",
      "|2024-01-11 10:59:54|App Web|Clips|a-c...|157,120,160,104,1...|47473af2-658d-4f4...|\n",
      "|2024-01-11 10:58:31|news| Shark attac...|127,157,120,160,1...|de022eeb-c303-441...|\n",
      "|2024-01-11 10:58:55|news| Video shows...|127,157,120,160,1...|56710419-baab-456...|\n",
      "|2024-01-11 10:59:44|App Web|Clips|the...|157,120,160,104,1...|a115104d-7fbd-491...|\n",
      "|2024-01-11 10:57:55|App Web|Clips|tod...|127,157,120,160,1...|507bcb1d-b419-472...|\n",
      "|2024-01-11 10:30:46|App Web|Clips|a-c...|157,120,160,104,1...|c176fede-c48e-4d4...|\n",
      "|2024-01-11 10:30:04|App Web|Clips|a-c...|127,157,120,160,1...|7e38440c-13bf-420...|\n",
      "|2024-01-11 10:30:53|news| Shark attac...|127,157,120,160,1...|8538f635-9e23-479...|\n",
      "|2024-01-11 10:30:08|news|Pint-sized A...|157,120,160,104,1...|5b4326d3-3dd4-4f3...|\n",
      "|2024-01-11 10:30:37|news| Shark attac...|127,157,120,160,1...|ba5113fa-8e63-4d9...|\n",
      "|2024-01-11 10:30:09|news| Child pulle...|157,120,160,104,1...|adb5dbea-5dc7-4e2...|\n",
      "|2024-01-11 10:30:25|news| Chilean nav...|157,120,160,104,1...|66a5ddd3-e6f6-4af...|\n",
      "|2024-01-11 10:30:51|news| Video shows...|157,120,160,104,1...|2f814b12-bbb3-4a8...|\n",
      "|               NULL|App Web|Clips|tod...|127,157,120,160,1...|90e9882f-e0cd-4c0...|\n",
      "|2024-01-11 10:30:23|news| Australian ...|127,157,120,160,1...|791c5cdc-6821-4d0...|\n",
      "+-------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# 假设 id_df 是一个包含 ID 的 DataFrame，video_plays_df 是视频播放信息的 DataFrame\n",
    "\n",
    "# 将 id_df 转换为 Pandas DataFrame，并随机选择其中的 ID\n",
    "id_pandas_df = df_user_id.toPandas()\n",
    "random_ids = id_pandas_df[\"id\"].tolist()\n",
    "random.shuffle(random_ids)\n",
    "\n",
    "# 定义一个函数来随机选择 ID\n",
    "def assign_random_id():\n",
    "    return random.choice(random_ids)\n",
    "\n",
    "\n",
    "# 注册 UDF\n",
    "assign_random_id_udf = udf(assign_random_id, StringType())\n",
    "\n",
    "# # 给 video_plays_df 添加一个名为 \"id\" 的列，值为随机选择的 ID\n",
    "df = df.withColumn(\"id\", assign_random_id_udf())\n",
    "\n",
    "# # 显示添加了 ID 列后的 DataFrame\n",
    "df.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import rand\n",
    "file_name = rf\"F:\\申请，润\\我去澳洲\\university of adelaide\\AWS\\ETL\\data_source1\"\n",
    "#异常值写入csv日志\n",
    "\n",
    "df.orderBy(rand()).limit(2000).coalesce(1).write.csv(file_name, header=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
