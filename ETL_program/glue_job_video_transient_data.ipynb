{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datalake transient/temperary zone: extract files for landing mechanism\n",
    "# implemented by lambda or airflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Key': 'video_data_new.csv', 'LastModified': datetime.datetime(2024, 7, 5, 2, 52, 57, tzinfo=tzutc()), 'ETag': '\"dbc7907b5835dd80907cb96936a7138e-8\"', 'Size': 133953954, 'StorageClass': 'STANDARD'}, {'Key': 'video_data_new_id.csv', 'LastModified': datetime.datetime(2024, 7, 10, 6, 21, 30, tzinfo=tzutc()), 'ETag': '\"c0f83d1c0608ea15dcc09aadd98c6795-10\"', 'Size': 162265146, 'StorageClass': 'STANDARD'}, {'Key': 'video_data_new_id_2024-07-09.csv', 'LastModified': datetime.datetime(2024, 7, 10, 6, 50, 57, tzinfo=tzutc()), 'ETag': '\"c0f83d1c0608ea15dcc09aadd98c6795-10\"', 'Size': 162265146, 'StorageClass': 'STANDARD'}, {'Key': 'video_data_new_id_20240709.csv', 'LastModified': datetime.datetime(2024, 7, 10, 6, 50, 57, tzinfo=tzutc()), 'ETag': '\"c0f83d1c0608ea15dcc09aadd98c6795-10\"', 'Size': 162265146, 'StorageClass': 'STANDARD'}, {'Key': 'video_data_new_id_limit_20240710.csv', 'LastModified': datetime.datetime(2024, 7, 11, 4, 31, 7, tzinfo=tzutc()), 'ETag': '\"998488a6acf6dfea39ab4deea72c7285\"', 'Size': 309229, 'StorageClass': 'STANDARD'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import boto3\n",
    "s3 = boto3.client('s3')\n",
    "result = s3.list_objects_v2(Bucket='video-source-data')\n",
    "\n",
    "print(result[\"Contents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-09\n",
      "20240709\n",
      "20240710\n",
      "video_data_new_id_limit_20240710.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['video_data_new_id_limit_20240710.csv']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "from datetime import *\n",
    "import re\n",
    "\n",
    "def list_files_with_date(bucket_name):\n",
    "    s3 = boto3.client('s3')\n",
    "    result = s3.list_objects_v2(Bucket=bucket_name)\n",
    "    files_to_move = []\n",
    "\n",
    "    date_patterns = [\n",
    "        r'\\d{4}-\\d{2}-\\d{2}',  # YYYY-MM-DD\n",
    "        r'\\d{4}\\d{2}\\d{2}',    # YYYYMMDD\n",
    "        r'\\d{2}-\\d{2}-\\d{4}',  # DD-MM-YYYY\n",
    "        r'\\d{2}/\\d{2}/\\d{4}',  # DD/MM/YYYY\n",
    "        r'\\d{4}\\\\\\d{2}\\\\\\d{2}', # YYYY\\MM\\DD\n",
    "        r'\\d{4}/\\d{2}/\\d{2}',   # YYYY/MM/DD\n",
    "        # Add more patterns as needed\n",
    "    ]\n",
    "\n",
    "    yesterday = (datetime.now() - timedelta(1)).date()\n",
    "\n",
    "    if 'Contents' in result:\n",
    "        for obj in result['Contents']:\n",
    "            if obj['Key'].endswith('.csv'):  # 检查是否是CSV文件\n",
    "                for pattern in date_patterns:\n",
    "                    match = re.search(pattern, obj['Key'])\n",
    "                    if match:\n",
    "                        date_str = match.group()\n",
    "                        print(date_str)\n",
    "                        try:\n",
    "                            if '\\\\' in date_str:\n",
    "                                date_str = date_str.replace('\\\\', '-')\n",
    "                            file_date = datetime.strptime(date_str, '%Y-%m-%d').date()\n",
    "                        except ValueError:\n",
    "                            try:\n",
    "                                file_date = datetime.strptime(date_str, '%Y%m%d').date()\n",
    "                            except ValueError:\n",
    "                                try:\n",
    "                                    file_date = datetime.strptime(date_str, '%d-%m-%Y').date()\n",
    "                                except ValueError:\n",
    "                                    try:\n",
    "                                        file_date = datetime.strptime(date_str, '%d/%m/%Y').date()\n",
    "                                    except ValueError:\n",
    "                                        try:\n",
    "                                            file_date = datetime.strptime(date_str, '%Y/%m/%d').date()\n",
    "                                        except ValueError:\n",
    "                                            continue\n",
    "                        if file_date == yesterday:\n",
    "                            print(obj['Key'])\n",
    "                            files_to_move.append(obj['Key'])\n",
    "                            break\n",
    "    \n",
    "    return files_to_move\n",
    "\n",
    "list_files_with_date('video-source-data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s3://your-raw-bucket/\n",
    "s3://your-staging-bucket/\n",
    "s3://your-curated-bucket/\n",
    "s3://your-analytical-bucket/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-09\n",
      "20240709\n",
      "20240710\n",
      "video_data_new_id_limit_20240710.csv\n",
      "File video_data_new_id_limit_20240710.csv moved from video-source-data to video-transient-bucket/2024-07-11/video_data_new_id_limit_20240710.csv\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "from datetime import *\n",
    "\n",
    "def move_s3_object(src_bucket_name, src_object_name, dest_bucket_name, dest_object_name):\n",
    "    s3 = boto3.resource('s3')\n",
    "    try:\n",
    "        # Copy the object to the new location\n",
    "        copy_source = {\n",
    "            'Bucket': src_bucket_name,\n",
    "            'Key': src_object_name\n",
    "        }\n",
    "        s3.meta.client.copy(copy_source, dest_bucket_name, dest_object_name)\n",
    "        \n",
    "        print(f\"File {src_object_name} moved from {src_bucket_name} to {dest_bucket_name}/{dest_object_name}\")\n",
    "    except NoCredentialsError:\n",
    "        print(\"Credentials not available\")\n",
    "\n",
    "# Replace these values with your bucket names\n",
    "src_bucket_name = 'video-source-data'\n",
    "dest_bucket_name = 'video-transient-bucket'\n",
    "\n",
    "folder_name = datetime.now().strftime('%Y-%m-%d')  # 目标文件夹路径\n",
    "\n",
    "files_to_move = list_files_with_date(src_bucket_name)\n",
    "\n",
    "for file_key in files_to_move:\n",
    "    dest_key = f'{folder_name}/{file_key.split(\"/\")[-1]}'  # 将文件移到目标文件夹\n",
    "    move_s3_object(src_bucket_name, file_key, dest_bucket_name, dest_key)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
